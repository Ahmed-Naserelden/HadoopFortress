172.21.0.4:8485: Journal Storage Directory root= /tmp/hadoop/dfs/journalnode/mycluster; location= null not formatted ; journal id: mycluster
        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkFormatted(Journal.java:531)
        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:721)
        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:229)
        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:230)
        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:31934)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)

172.21.0.3:8485: Journal Storage Directory root= /tmp/hadoop/dfs/journalnode/mycluster; location= null not formatted ; journal id: mycluster
        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkFormatted(Journal.java:531)
        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:721)
        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:229)
        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:230)
        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:31934)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)

172.21.0.2:8485: Journal Storage Directory root= /tmp/hadoop/dfs/journalnode/mycluster; location= null not formatted ; journal id: mycluster
        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkFormatted(Journal.java:531)
        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:721)
        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:229)
        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:230)
        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:31934)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)

        at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
        at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:305)
        at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:143)
        at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectStreamingInputStreams(QuorumJournalManager.java:619)
        at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:535)
        at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:276)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1725)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1758)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1737)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:717)
        at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:339)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1236)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:808)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:694)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:781)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1033)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1008)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1782)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1847)
2025-03-23 08:20:09,380 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2025-03-23 08:20:09,380 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/usr/local/hadoop/yarn_data/hdfs/namenode/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2025-03-23 08:20:09,432 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2025-03-23 08:20:09,440 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Successfully loaded 1 inodes
2025-03-23 08:20:09,447 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Completed update blocks map and name cache, total waiting duration 0ms.
2025-03-23 08:20:09,452 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2025-03-23 08:20:09,452 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /usr/local/hadoop/yarn_data/hdfs/namenode/current/fsimage_0000000000000000000
2025-03-23 08:20:09,456 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2025-03-23 08:20:09,457 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2025-03-23 08:20:09,457 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 500 msecs
2025-03-23 08:20:09,811 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master1:8020
2025-03-23 08:20:09,811 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Enable NameNode state context:false
2025-03-23 08:20:09,815 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-03-23 08:20:09,830 INFO org.apache.hadoop.ipc.Server: Listener at master1:8020
2025-03-23 08:20:09,833 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2025-03-23 08:20:09,906 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2025-03-23 08:20:09,915 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2025-03-23 08:20:09,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor: Initialized the Default Decommission and Maintenance monitor
2025-03-23 08:20:09,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Start MarkedDeleteBlockScrubber thread
2025-03-23 08:20:09,926 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2025-03-23 08:20:09,926 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2025-03-23 08:20:09,926 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2025-03-23 08:20:09,971 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2025-03-23 08:20:09,971 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2025-03-23 08:20:09,983 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master1/172.21.0.3:8020
2025-03-23 08:20:09,987 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2025-03-23 08:20:09,994 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node every 120 seconds.
2025-03-23 08:20:10,004 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://master2:9870, http://master3:9870]
Serving checkpoints at http://master1:9870
2025-03-23 08:20:10,009 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [172.21.0.3:8485, 172.21.0.4:8485, 172.21.0.2:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
172.21.0.4:8485: Journal Storage Directory root= /tmp/hadoop/dfs/journalnode/mycluster; location= null not formatted ; journal id: mycluster
        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkFormatted(Journal.java:531)
        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:721)
        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:229)
        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:230)
        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:31934)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)

172.21.0.3:8485: Journal Storage Directory root= /tmp/hadoop/dfs/journalnode/mycluster; location= null not formatted ; journal id: mycluster
        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkFormatted(Journal.java:531)
        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:721)
        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:229)
        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:230)
        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:31934)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)

172.21.0.2:8485: Journal Storage Directory root= /tmp/hadoop/dfs/journalnode/mycluster; location= null not formatted ; journal id: mycluster
        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkFormatted(Journal.java:531)
        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:721)
        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:229)
        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:230)
        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:31934)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)

        at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
        at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:305)
        at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:143)
        at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectStreamingInputStreams(QuorumJournalManager.java:619)
        at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:535)
        at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:276)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1725)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1758)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:341)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:504)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:450)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:467)
        at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:516)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:463)
2025-03-23 08:20:10,565 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /usr/local/hadoop/yarn_data/hdfs/namenode/current/fsimage_0000000000000000000, fileSize: 401. Sent total: 401 bytes. Size of last segment intended to send: -1 bytes.
2025-03-23 08:20:10,568 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /usr/local/hadoop/yarn_data/hdfs/namenode/current/fsimage_0000000000000000000, fileSize: 401. Sent total: 401 bytes. Size of last segment intended to send: -1 bytes.
2025-03-23 08:20:14,484 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.21.0.3:9866, datanodeUuid=4493408f-1c47-4339-9a5a-7aaaadd2be9a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-46b1a6bf-2556-4c4d-b9c8-d07e22271277;nsid=470642279;c=1742718005808) storage 4493408f-1c47-4339-9a5a-7aaaadd2be9a
2025-03-23 08:20:14,498 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.21.0.3:9866
2025-03-23 08:20:14,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 4493408f-1c47-4339-9a5a-7aaaadd2be9a (172.21.0.3:9866).
2025-03-23 08:20:14,719 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-63eb06d5-2999-4658-8eb8-c66a63e3832e for DN 172.21.0.3:9866
2025-03-23 08:20:14,867 INFO BlockStateChange: BLOCK* processReport 0xdf3a1ea1ed35cf3f with lease ID 0x8b5e7f6704f7b4d0: Processing first storage report for DS-63eb06d5-2999-4658-8eb8-c66a63e3832e from datanode DatanodeRegistration(172.21.0.3:9866, datanodeUuid=4493408f-1c47-4339-9a5a-7aaaadd2be9a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-46b1a6bf-2556-4c4d-b9c8-d07e22271277;nsid=470642279;c=1742718005808)
2025-03-23 08:20:14,869 INFO BlockStateChange: BLOCK* processReport 0xdf3a1ea1ed35cf3f with lease ID 0x8b5e7f6704f7b4d0: from storage DS-63eb06d5-2999-4658-8eb8-c66a63e3832e node DatanodeRegistration(172.21.0.3:9866, datanodeUuid=4493408f-1c47-4339-9a5a-7aaaadd2be9a, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-46b1a6bf-2556-4c4d-b9c8-d07e22271277;nsid=470642279;c=1742718005808), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2025-03-23 08:20:24,630 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.21.0.2:9866, datanodeUuid=5ab0b67b-10e4-46dc-9f1f-0c2172f93de6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-46b1a6bf-2556-4c4d-b9c8-d07e22271277;nsid=470642279;c=1742718005808) storage 5ab0b67b-10e4-46dc-9f1f-0c2172f93de6
2025-03-23 08:20:24,630 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.21.0.2:9866
2025-03-23 08:20:24,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 5ab0b67b-10e4-46dc-9f1f-0c2172f93de6 (172.21.0.2:9866).
2025-03-23 08:20:24,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.21.0.4:9866, datanodeUuid=917c8ec7-e7c0-4e4f-9284-9de981a61358, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-46b1a6bf-2556-4c4d-b9c8-d07e22271277;nsid=470642279;c=1742718005808) storage 917c8ec7-e7c0-4e4f-9284-9de981a61358
2025-03-23 08:20:24,685 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/172.21.0.4:9866
2025-03-23 08:20:24,685 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 917c8ec7-e7c0-4e4f-9284-9de981a61358 (172.21.0.4:9866).
2025-03-23 08:20:24,744 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-9ca415fd-389b-4355-ad9e-0e0b3e6b368e for DN 172.21.0.2:9866
2025-03-23 08:20:24,772 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-ae144e3a-c704-4bb5-8371-2056ced05a16 for DN 172.21.0.4:9866
2025-03-23 08:20:24,787 INFO BlockStateChange: BLOCK* processReport 0x1ea7c3d5ac7f9011 with lease ID 0x8b5e7f6704f7b4d1: Processing first storage report for DS-9ca415fd-389b-4355-ad9e-0e0b3e6b368e from datanode DatanodeRegistration(172.21.0.2:9866, datanodeUuid=5ab0b67b-10e4-46dc-9f1f-0c2172f93de6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-46b1a6bf-2556-4c4d-b9c8-d07e22271277;nsid=470642279;c=1742718005808)
2025-03-23 08:20:24,787 INFO BlockStateChange: BLOCK* processReport 0x1ea7c3d5ac7f9011 with lease ID 0x8b5e7f6704f7b4d1: from storage DS-9ca415fd-389b-4355-ad9e-0e0b3e6b368e node DatanodeRegistration(172.21.0.2:9866, datanodeUuid=5ab0b67b-10e4-46dc-9f1f-0c2172f93de6, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-46b1a6bf-2556-4c4d-b9c8-d07e22271277;nsid=470642279;c=1742718005808), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-23 08:20:24,815 INFO BlockStateChange: BLOCK* processReport 0x9f0c5ec3a65f4180 with lease ID 0x8b5e7f6704f7b4d2: Processing first storage report for DS-ae144e3a-c704-4bb5-8371-2056ced05a16 from datanode DatanodeRegistration(172.21.0.4:9866, datanodeUuid=917c8ec7-e7c0-4e4f-9284-9de981a61358, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-46b1a6bf-2556-4c4d-b9c8-d07e22271277;nsid=470642279;c=1742718005808)
2025-03-23 08:20:24,815 INFO BlockStateChange: BLOCK* processReport 0x9f0c5ec3a65f4180 with lease ID 0x8b5e7f6704f7b4d2: from storage DS-ae144e3a-c704-4bb5-8371-2056ced05a16 node DatanodeRegistration(172.21.0.4:9866, datanodeUuid=917c8ec7-e7c0-4e4f-9284-9de981a61358, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-46b1a6bf-2556-4c4d-b9c8-d07e22271277;nsid=470642279;c=1742718005808), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2025-03-23 08:21:10,018 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [172.21.0.3:8485, 172.21.0.4:8485, 172.21.0.2:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
172.21.0.4:8485: Journal Storage Directory root= /tmp/hadoop/dfs/journalnode/mycluster; location= null not formatted ; journal id: mycluster
        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkFormatted(Journal.java:531)
        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:721)
        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:229)
        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:230)
        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:31934)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)

172.21.0.3:8485: Journal Storage Directory root= /tmp/hadoop/dfs/journalnode/mycluster; location= null not formatted ; journal id: mycluster
        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkFormatted(Journal.java:531)
        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:721)
        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:229)
        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:230)
        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:31934)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)

172.21.0.2:8485: Journal Storage Directory root= /tmp/hadoop/dfs/journalnode/mycluster; location= null not formatted ; journal id: mycluster
        at org.apache.hadoop.hdfs.qjournal.server.Journal.checkFormatted(Journal.java:531)
        at org.apache.hadoop.hdfs.qjournal.server.Journal.getEditLogManifest(Journal.java:721)
        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.getEditLogManifest(JournalNodeRpcServer.java:229)
        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.getEditLogManifest(QJournalProtocolServerSideTranslatorPB.java:230)
        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:31934)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)

        at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
        at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:305)
        at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:143)
        at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectStreamingInputStreams(QuorumJournalManager.java:619)
        at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:535)
        at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:276)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1725)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1758)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:341)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:504)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:450)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:467)
        at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:516)
        at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:463)
hduser@master1:/usr/local/hadoop/logs$ 